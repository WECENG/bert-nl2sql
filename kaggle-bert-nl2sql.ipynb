{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7335893,"sourceType":"datasetVersion","datasetId":4258769},{"sourceId":7335929,"sourceType":"datasetVersion","datasetId":4258788},{"sourceId":7359762,"sourceType":"datasetVersion","datasetId":4274874},{"sourceId":7382671,"sourceType":"datasetVersion","datasetId":4290692},{"sourceId":7410921,"sourceType":"datasetVersion","datasetId":4310498}],"dockerImageVersionId":30627,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import\nimport numpy as np\nimport pandas as pd\nimport torch.utils.data\nimport torch.cuda\nimport json\nfrom transformers import BertTokenizer,BertModel\nfrom torch import nn\nfrom sklearn import metrics\nfrom torch.optim.adam import Adam\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm import tqdm\nfrom typing import List","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-16T03:48:17.766739Z","iopub.execute_input":"2024-01-16T03:48:17.767100Z","iopub.status.idle":"2024-01-16T03:48:21.255648Z","shell.execute_reply.started":"2024-01-16T03:48:17.767062Z","shell.execute_reply":"2024-01-16T03:48:21.254849Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"#util\ndef read_train_datas(path, question_length, columns):\n    \"\"\"\n    :param path 数据路径\n    :param question_length 问题长度\n    :param columns 列\n    :return: [[question, agg, conn_op, cond_ops, cond_vals],...], cond_vals:[[val_start_idx,val_end_idx],...]\n    \"\"\"\n    column_length = len(columns)\n    with open(path, 'r', encoding='utf-8') as f:\n        data_list = []\n        for line in f:\n            item = json.loads(line)\n            # question\n            question = item['question']\n            # agg\n            sel = item['sql']['sel']\n            agg_op = item['sql']['agg']\n            agg = [get_agg_dict()['none']] * column_length\n            for i in range(len(sel)):\n                sel_col_item = sel[i]\n                agg_op_item = agg_op[i]\n                agg[sel_col_item] = agg_op_item\n            # conn_op\n            conn_op = item['sql']['cond_conn_op']\n            # cond_cols & cond_ops & cond_vals\n            # +1 默认初始化为不存在的列, question_length需要大于column_length\n            cond_cols = [column_length + 1] * question_length\n            cond_ops = [get_cond_op_dict()['none']] * question_length\n            cond_vals = [0] * question_length\n            if item['sql'].get('conds') is not None:\n                conds = item['sql']['conds']\n                for idx, cond in enumerate(conds):\n                    cond_cols[idx] = cond[0]\n                    cond_ops[idx] = cond[1]\n                    value = cond[2]\n                    cond_vals = fill_value_start_end(cond_vals, question, value, idx)\n            data_list.append([question, agg, conn_op, cond_cols, cond_ops, cond_vals])\n    return data_list\n\n\ndef read_predict_datas(path):\n    \"\"\"\n    :param path: 预测数据路径\n    :return: 预测数据\n    \"\"\"\n    questions = []\n    with open(path, 'r', encoding='utf-8') as f:\n        for line in f:\n            item = json.loads(line)\n            question = item['question']\n            questions.append([question])\n    return questions\n\n\ndef get_columns(table_path):\n    columns = pd.read_table(table_path, header=2)\n    return columns.columns.__array__()\n\n\ndef get_cond_op_dict():\n    cond_op_dict = {'>': 0, '<': 1, '==': 2, '!=': 3, 'like': 4, '>=': 5, '<=': 6, 'none': 7}\n    return cond_op_dict\n\n\ndef get_conn_op_dict():\n    conn_op_dict = {'none': 0, 'and': 1, 'or': 2}\n    return conn_op_dict\n\n\ndef get_agg_dict():\n    agg_dict = {'': 0, 'AVG': 1, 'MAX': 2, 'MIN': 3, 'COUNT': 4, 'SUM': 5, 'none': 6}\n    return agg_dict\n\n\ndef get_key(dict, value):\n    \"\"\"\n    根据字典的value获取key\n    :param dict: 字典\n    :param value: 值\n    :return: key\n    \"\"\"\n    return [k for k, v in dict.items() if v == value]\n\n\ndef fill_value_start_end(cond_vals, question, value, idx):\n    \"\"\"\n    :param cond_vals 待填充待值\n    :param question 问题\n    :param value 待匹配待值\n    :param 下标\n    fill [1] by the value in the question\n    结果类似[0,0,0,0,1,1,1,1,0,0,0,2,2,2,2,3,3,3,0,0,0,4,4,4,0,0,0,0,0]\n    \"\"\"\n    question_length = len(question)\n    value_length = len(value)\n    for i in range(question_length - value_length + 1):\n        if question[i:value_length + i] == value:\n            cond_vals[i: value_length + i] = [idx + 1] * value_length\n    return cond_vals\n\n\ndef count_values(cond_vals):\n    \"\"\"\n   cond_vals的值如[0,0,0,0,1,1,1,1,0,0,0,2,2,2,2,3,3,3,0,0,0,4,4,4,0,0,0,0,0]所示\n   统计出现>0的数量，连续的>0只统计一次\n   \"\"\"\n    count = 0\n    pre_value = None\n    for idx, val in enumerate(cond_vals):\n        if idx > 0:\n            pre_value = cond_vals[idx - 1]\n        if val > 0 and val != pre_value:\n            count = count + 1\n    return count\n\n\ndef get_values_name(question, cond_vals):\n    \"\"\"\n    cond_vals的值如[0,0,0,0,1,1,1,1,0,0,0,2,2,2,2,3,3,3,0,0,0,4,4,4,0,0,0,0,0]所示\n    根据cond_vals中为1的值找到question对应下标的内容\n    返回找到的内容列表，连续为1的内容作为返回列表的一个元素\n    \"\"\"\n    result = []\n    start_of_segment = None\n    for idx, current_value in enumerate(cond_vals):\n        previous_value = cond_vals[idx - 1] if idx > 0 else None\n        # 检测新的连续段的开始\n        if current_value > 0 and current_value != previous_value and start_of_segment is None:\n            start_of_segment = idx\n        # 当段结束时，添加到结果并更新段的起始位置\n        elif current_value != previous_value and start_of_segment is not None:\n            segment = question[start_of_segment:idx]\n            result.append(segment)\n            start_of_segment = None if current_value == 0 else idx\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T03:48:22.482914Z","iopub.execute_input":"2024-01-16T03:48:22.483904Z","iopub.status.idle":"2024-01-16T03:48:22.507008Z","shell.execute_reply.started":"2024-01-16T03:48:22.483867Z","shell.execute_reply":"2024-01-16T03:48:22.506086Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#dataset\n# label\nclass Label(object):\n    def __init__(self, label_agg: List = None, label_conn_op=None, label_cond_cols: List = None,\n                 label_cond_ops: List = None, label_cond_vals: List = None):\n        \"\"\"\n        训练标签信息\n        :param label_agg: 聚合函数\n        :param label_conn_op: 连接操作符\n        :param label_cond_cols: 条件操列\n        :param label_cond_ops: 条件操作符\n        :param label_cond_vals: 条件值\n        \"\"\"\n        self.label_agg = label_agg\n        self.label_conn_op = label_conn_op\n        self.label_cond_ops = label_cond_ops\n        self.label_cond_cols = label_cond_cols\n        self.label_cond_vals = label_cond_vals\n\n\nclass InputFeatures(object):\n    def __init__(self, model_path=None, question_length=128, max_length=512, input_ids=None, attention_mask=None,\n                 token_type_ids=None, cls_idx=None, label: Label = None):\n        if model_path is not None:\n            self.tokenizer = BertTokenizer.from_pretrained(model_path)\n        self.question_length = question_length\n        self.max_length = max_length\n        self.input_ids = input_ids\n        self.attention_mask = attention_mask\n        self.token_type_ids = token_type_ids\n        self.cls_idx = cls_idx\n        self.label = label\n\n    def encode_expression(self, expressions: List):\n        \"\"\"\n        表达式编码\n        :param expressions: 表达式（列名或条件表达式）\n        :return: 编码后的列，及序列号（用于列与列之间的区分）\n        \"\"\"\n        encodings = self.tokenizer.batch_encode_plus(expressions)\n        expressions_encode = encodings[\"input_ids\"]\n        segment_ids = encodings[\"token_type_ids\"]\n        segment_ids = [[elem if j % 2 == 0 else 1 for elem in row] for j, row in enumerate(segment_ids)]\n        expressions_encode = [item for sublist in expressions_encode for item in sublist]\n        segment_ids = [item for sublist in segment_ids for item in sublist]\n        return torch.tensor(expressions_encode), torch.tensor(segment_ids)\n\n    def get_cls_idx(self, expressions):\n        \"\"\"\n        获取表达式标记符的位置\n        :param expressions: 表达式\n        :return:\n        \"\"\"\n        cls_idx = []\n        start = self.question_length\n        for i in range(len(expressions)):\n            cls_idx.append(int(start))\n            # 加上特殊标记的长度（例如 [CLS] 和 [SEP]）\n            start += len(expressions[i]) + 2\n        return cls_idx\n\n    def encode_question_with_expressions(self, que_length, max_length, question, expressions_encode,\n                                         expressions_segment_id):\n        \"\"\"\n        编码\n        :param que_length: 问题长度\n        :param max_length: text长度\n        :param question:  问题\n        :param expressions_encode:  编码的列\n        :param expressions_segment_id 编码的列的序列\n        :return: 编码后的text\n        \"\"\"\n\n        # 编码问题，需要填充，否则会出现长度不一致异常\n        question_encoding = self.tokenizer.encode(question, add_special_tokens=True, padding='max_length',\n                                                  max_length=que_length, truncation=True)\n\n        # 合并编码后的张量，保证张量类型(dtype)为int或long, bert的embedding的要求\n        input_ids = torch.cat([torch.tensor(question_encoding), expressions_encode], dim=0)\n        token_type_ids = torch.cat([torch.zeros(que_length, dtype=torch.long), expressions_segment_id], dim=0)\n        padding_length = max_length - len(input_ids)\n        attention_mask = torch.cat([torch.ones(len(input_ids)), torch.zeros(padding_length)], dim=0)\n        input_ids = torch.cat([input_ids, torch.zeros(padding_length, dtype=torch.long)], dim=0)\n        token_type_ids = torch.cat([token_type_ids, torch.zeros(padding_length, dtype=torch.long)], dim=0)\n\n        return input_ids, attention_mask, token_type_ids\n\n    def list_features(self, columns, datas):\n        \"\"\"\n        输入特征\n        :param columns 列\n        :param datas: 数据\n        :return: 特征信息\n        \"\"\"\n        list_features = []\n        cls_idx = self.get_cls_idx(columns)\n        expressions_encode, expressions_segment_id = self.encode_expression(columns)\n        for data in datas:\n            question = data[0]\n            # if contain label data\n            label = None\n            if len(data) > 1:\n                label = Label(label_agg=data[1], label_conn_op=data[2], label_cond_cols=data[3], label_cond_ops=data[4],\n                              label_cond_vals=data[5])\n            # 编码(question+expressions)\n            input_ids, attention_mask, token_type_ids = self.encode_question_with_expressions(self.question_length,\n                                                                                              self.max_length,\n                                                                                              question,\n                                                                                              expressions_encode,\n                                                                                              expressions_segment_id)\n            list_features.append(\n                InputFeatures(question_length=self.question_length, max_length=self.max_length, input_ids=input_ids,\n                              attention_mask=attention_mask, token_type_ids=token_type_ids, cls_idx=cls_idx,\n                              label=label))\n        return list_features\n\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, features: List[InputFeatures]):\n        self.features = features\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, item):\n        feature = self.features[item]\n        input_ids = np.array(feature.input_ids)\n        attention_mask = np.array(feature.attention_mask)\n        token_type_ids = np.array(feature.token_type_ids)\n        cls_idx = np.array(feature.cls_idx)\n        if feature.label is not None:\n            label: Label = feature.label\n            label_agg = np.array(label.label_agg)\n            label_conn_op = np.array(label.label_conn_op)\n            label_cond_cols = np.array(label.label_cond_cols)\n            label_cond_ops = np.array(label.label_cond_ops)\n            label_cond_vals = np.array([np.array(val) for val in label.label_cond_vals])\n            return input_ids, attention_mask, token_type_ids, cls_idx, label_agg, label_conn_op, label_cond_cols, label_cond_ops, label_cond_vals\n        else:\n            return input_ids, attention_mask, token_type_ids, cls_idx\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T03:48:23.694801Z","iopub.execute_input":"2024-01-16T03:48:23.695140Z","iopub.status.idle":"2024-01-16T03:48:23.720034Z","shell.execute_reply.started":"2024-01-16T03:48:23.695114Z","shell.execute_reply":"2024-01-16T03:48:23.719036Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#model\nclass ColClassifierModel(nn.Module):\n    def __init__(self, model_path, hidden_size, agg_length, conn_op_length, dropout=0.5):\n        super(ColClassifierModel, self).__init__()\n        self.bert = BertModel.from_pretrained(model_path)\n        self.dropout = nn.Dropout(dropout)\n        # out classes需要纬度必须大于label中size(classes)，否则会出现Assertion `t >= 0 && t < n_classes` failed.\n        self.agg_classifier = nn.Linear(hidden_size, agg_length)\n        self.conn_op_classifier = nn.Linear(hidden_size, conn_op_length)\n\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, cls_idx=None):\n        # 输出最后一层隐藏状态以及池化层\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        dropout_output = self.dropout(outputs.pooler_output)\n        dropout_hidden_state = self.dropout(outputs.last_hidden_state)\n\n        \"\"\"\n        提取列特征信息，从dim=1即第二维中（列标记符号索引所在纬度）提取dropout_hidden_state对应该纬度的信息。\n        前提需要将cls_idx张量shape扩展成与dropout_hidden_state一致\n        \"\"\"\n        # cls_cols = dropout_hidden_state.gather(dim=1, index=cls_idx.unsqueeze(-1).expand(\n        #     dropout_hidden_state.shape[0], -1, dropout_hidden_state.shape[-1]))\n        # 简化写法\n        cls_cols = dropout_hidden_state[:, cls_idx[0], :]\n\n        out_agg = self.agg_classifier(cls_cols)\n\n        out_conn_op = self.conn_op_classifier(dropout_output)\n\n        return out_agg, out_conn_op\n\n\nclass CondClassifierModel(nn.Module):\n    def __init__(self, model_path, hidden_size, question_length, dropout=0.5):\n        super(CondClassifierModel, self).__init__()\n        self.bert = BertModel.from_pretrained(model_path)\n        self.dropout = nn.Dropout(dropout)\n        # question_length为条件最多个数\n        self.cond_cols_classifier = nn.Linear(hidden_size, question_length)\n        self.cond_ops_classifier = nn.Linear(hidden_size, question_length)\n        self.cond_vals_classifier = nn.Linear(hidden_size, question_length)\n        self.cond_count_classifier = nn.Linear(hidden_size, question_length)\n        self.question_length = question_length\n\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n        # 输出最后一层隐藏状态\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        dropout_output = self.dropout(outputs.pooler_output)\n        hidden_state = outputs.last_hidden_state\n\n        out_cond_count = self.cond_count_classifier(dropout_output)\n\n        # 提取问题特征信息\n        cond_values = hidden_state[:, 1:self.question_length + 1, :]\n\n        out_cond_cols = self.cond_cols_classifier(cond_values)\n        out_cond_ops = self.cond_ops_classifier(cond_values)\n        out_cond_vals = self.cond_vals_classifier(cond_values)\n\n        return out_cond_cols, out_cond_ops, out_cond_vals, out_cond_count\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T03:48:24.885021Z","iopub.execute_input":"2024-01-16T03:48:24.885892Z","iopub.status.idle":"2024-01-16T03:48:24.899383Z","shell.execute_reply.started":"2024-01-16T03:48:24.885859Z","shell.execute_reply":"2024-01-16T03:48:24.898407Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#train\ndef train(model: ColClassifierModel or CondClassifierModel, model_save_path, train_dataset: Dataset,\n          val_dataset: Dataset, batch_size, lr, epochs):\n    # DataLoader根据batch_size获取数据，训练时选择打乱样本\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    # 是否使用gpu\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n    # 定义损失函数和优化器\n    criterion = nn.CrossEntropyLoss()\n    optim = Adam(model.parameters(), lr=lr)\n    if use_cuda:\n        model = model.to(device)\n        criterion = criterion.to(device)\n    best_val_avg_acc = 0\n    for epoch in range(epochs):\n        total_loss_train = 0\n        model.train()\n        # 训练进度\n        for input_ids, attention_mask, token_type_ids, cls_idx, label_agg, label_conn_op, label_cond_cols, label_cond_ops, label_cond_vals in tqdm(\n                train_loader):\n            # model要求输入的矩阵(hidden_size,sequence_size),需要把第二纬度去除.squeeze(1)\n            input_ids = input_ids.squeeze(1).to(device)\n            attention_mask = attention_mask.to(device)\n            token_type_ids = token_type_ids.squeeze(1).to(device)\n            if type(model) is ColClassifierModel:\n                # reshape(-1)合并一二纬度\n                label_agg = label_agg.to(device).reshape(-1)\n                label_conn_op = label_conn_op.to(device)\n                # 模型输出\n                out_agg, out_conn_op = model(input_ids, attention_mask, token_type_ids, cls_idx)\n                out_agg = out_agg.to(device).reshape(-1, out_agg.size(2))\n                out_conn_op = out_conn_op.to(device)\n                # 计算损失\n                loss_agg = criterion(out_agg, label_agg)\n                loss_conn_op = criterion(out_conn_op, label_conn_op)\n                # 损失比例\n                total_loss_train = loss_agg + loss_conn_op\n\n            if type(model) is CondClassifierModel:\n                label_cond_cols = label_cond_cols.to(device).reshape(-1)\n                label_cond_ops = label_cond_ops.to(device).reshape(-1)\n                label_cond_vals = label_cond_vals.to(device)\n                label_cond_count = [count_values(label_cond_val) for label_cond_val in label_cond_vals]\n                label_cond_count = torch.tensor(label_cond_count).reshape(-1).to(device)\n                label_cond_vals = label_cond_vals.reshape(-1)\n                # 模型输出\n                out_cond_cols, out_cond_ops, out_cond_vals, out_cond_count = model(input_ids, attention_mask,\n                                                                                   token_type_ids)\n                # 计算损失\n                out_cond_cols = out_cond_cols.reshape(-1, out_cond_cols.size(2))\n                out_cond_ops = out_cond_ops.reshape(-1, out_cond_ops.size(2))\n                out_cond_vals = out_cond_vals.reshape(-1, out_cond_vals.size(2))\n                lost_cond_cols = criterion(out_cond_cols, label_cond_cols)\n                lost_cond_ops = criterion(out_cond_ops, label_cond_ops)\n                lost_cond_vals = criterion(out_cond_vals, label_cond_vals)\n                lost_cond_count = criterion(out_cond_count, label_cond_count)\n                total_loss_train = ((lost_cond_cols + lost_cond_vals + lost_cond_ops) * 0.1 + lost_cond_count * 0.9)\n\n            # 模型更新\n            model.zero_grad()\n            optim.zero_grad()\n            total_loss_train.backward()\n            optim.step()\n        # 模型验证\n        val_avg_acc = 0\n        out_all_agg = []\n        out_all_conn_op = []\n        out_all_cond_cols = []\n        out_all_cond_ops = []\n        out_all_cond_vals = []\n        out_all_cond_count = []\n        label_all_agg = []\n        label_all_conn_op = []\n        label_all_cond_cols = []\n        label_all_cond_ops = []\n        label_all_cond_vals = []\n        label_all_cond_count = []\n        # 验证无需梯度计算\n        model.eval()\n        with torch.no_grad():\n            # 使用当前epoch训练好的模型验证\n            for input_ids, attention_mask, token_type_ids, cls_idx, label_agg, label_conn_op, label_cond_cols, label_cond_ops, label_cond_vals in val_loader:\n                input_ids = input_ids.squeeze(1).to(device)\n                attention_mask = attention_mask.to(device)\n                token_type_ids = token_type_ids.squeeze(1).to(device)\n                if type(model) is ColClassifierModel:\n                    label_agg = label_agg.to(device).reshape(-1)\n                    label_conn_op = label_conn_op.to(device)\n                    # 模型输出\n                    out_agg, out_conn_op = model(input_ids, attention_mask, token_type_ids, cls_idx)\n                    out_agg = out_agg.argmax(dim=2).to(device).reshape(-1)\n                    out_conn_op = out_conn_op.argmax(dim=1).to(device)\n                    out_all_agg.append(out_agg.cpu().numpy())\n                    out_all_conn_op.append(out_conn_op.cpu().numpy())\n                    label_all_agg.append(label_agg.cpu().numpy())\n                    label_all_conn_op.append(label_conn_op.cpu().numpy())\n                if type(model) is CondClassifierModel:\n                    label_cond_cols = label_cond_cols.to(device).reshape(-1)\n                    label_cond_ops = label_cond_ops.to(device).reshape(-1)\n                    label_cond_vals = label_cond_vals.to(device)\n                    label_count_value = [count_values(label_cond_val) for label_cond_val in label_cond_vals]\n                    label_cond_vals = label_cond_vals.reshape(-1)\n                    # 模型输出\n                    out_cond_cols, out_cond_ops, out_cond_vals, out_cond_count = model(input_ids, attention_mask,\n                                                                                       token_type_ids)\n                    out_cond_cols = out_cond_cols.argmax(dim=2).to(device)\n                    out_cond_ops = out_cond_ops.argmax(dim=2).to(device)\n                    out_cond_vals = out_cond_vals.argmax(dim=2).to(device)\n                    out_cond_count = out_cond_count.argmax(dim=1).to(device)\n                    out_cond_cols = out_cond_cols.reshape(-1)\n                    out_cond_ops = out_cond_ops.reshape(-1)\n                    out_cond_vals = out_cond_vals.reshape(-1)\n                    out_all_cond_cols.append(out_cond_cols.cpu().numpy())\n                    out_all_cond_ops.append(out_cond_ops.cpu().numpy())\n                    out_all_cond_vals.append(out_cond_vals.cpu().numpy())\n                    out_all_cond_count.extend(out_cond_count.cpu().numpy())\n                    label_all_cond_cols.append(label_cond_cols.cpu().numpy())\n                    label_all_cond_ops.append(label_cond_ops.cpu().numpy())\n                    label_all_cond_vals.append(label_cond_vals.cpu().numpy())\n                    label_all_cond_count.extend(label_count_value)\n\n        if type(model) is ColClassifierModel:\n            val_agg_acc = metrics.accuracy_score(np.concatenate(out_all_agg, axis=0),\n                                                 np.concatenate(label_all_agg, axis=0))\n            val_conn_op_acc = metrics.accuracy_score(np.concatenate(out_all_conn_op, axis=0),\n                                                     np.concatenate(label_all_conn_op, axis=0))\n            print(f'val_agg_acc: {val_agg_acc}')\n            print(f'val_conn_op_acc: {val_conn_op_acc}')\n            # 准确率计算逻辑\n            val_avg_acc = (val_agg_acc + val_conn_op_acc) / 2\n        if type(model) is CondClassifierModel:\n            val_cond_cols_acc = metrics.accuracy_score(np.concatenate(out_all_cond_cols, axis=0),\n                                                       np.concatenate(label_all_cond_cols, axis=0))\n            val_cond_ops_acc = metrics.accuracy_score(np.concatenate(out_all_cond_ops, axis=0),\n                                                      np.concatenate(label_all_cond_ops, axis=0))\n            val_cond_vals_acc = metrics.accuracy_score(np.concatenate(out_all_cond_vals, axis=0),\n                                                       np.concatenate(label_all_cond_vals, axis=0))\n            val_cond_count_acc = metrics.accuracy_score(label_all_cond_count, out_all_cond_count)\n            print(f'val_cond_cols_acc: {val_cond_cols_acc}')\n            print(f'val_cond_ops_acc: {val_cond_ops_acc}')\n            print(f'val_cond_vals_acc: {val_cond_vals_acc}')\n            print(f'val_cond_count_acc: {val_cond_count_acc}')\n            val_avg_acc = (val_cond_cols_acc + val_cond_ops_acc + val_cond_vals_acc) / 3 * 0.1 + val_cond_count_acc * 0.9\n            # save model\n        if val_avg_acc > best_val_avg_acc:\n            best_val_avg_acc = val_avg_acc\n            torch.save(model.state_dict(), model_save_path)\n            print(f'''best model | Val Accuracy: {best_val_avg_acc: .4f}''')\n        print(\n            f'''Epochs: {epoch + 1} \n              | Train Loss: {total_loss_train.item(): .4f} \n              | Val Accuracy: {val_avg_acc: .4f}''')\n\n\nif __name__ == '__main__':\n    hidden_size = 768\n    batch_size = 12\n    learn_rate = 2e-5\n    epochs = 50\n    question_length = 128\n    max_length = 512\n    table_path = '/kaggle/input/bert-nl2sql-train-datas/table.xlsx'\n    train_data_path = '/kaggle/input/bert-nl2sql-train-datas/train.jsonl'\n    pretrain_model_path = '/kaggle/input/bert-nl2sql-chinese-model-hgd'\n    save_column_model_path = '/kaggle/working/classifier-column-model.pkl'\n    save_value_model_path = '/kaggle/working/classifier-value-model.pkl'\n    # 读取列\n    columns = get_columns(table_path)\n    # 加载数据\n    label_datas = read_train_datas(train_data_path, question_length, columns)\n    # 提取特征数据\n    model_features = InputFeatures(pretrain_model_path, question_length, max_length).list_features(columns, label_datas)\n    # 初始化dataset\n    model_dateset = Dataset(model_features)\n    # 创建模型\n    col_model = ColClassifierModel(pretrain_model_path, hidden_size, len(get_agg_dict()), len(get_conn_op_dict()))\n    # 分割数据集\n    total_size = len(label_datas)\n    train_size = int(0.8 * total_size)\n    val_size = int(0.1 * total_size)\n    test_size = total_size - train_size - val_size\n    # 分割数据集\n    model_train_dataset, model_val_dataset, model_test_dataset = random_split(model_dateset,\n                                                                              [train_size, val_size,\n                                                                               test_size])\n    print('train column model begin')\n    train(col_model, save_column_model_path, model_train_dataset, model_val_dataset, batch_size, learn_rate,\n          epochs)\n    print('train column model finish')\n    cond_model = CondClassifierModel(pretrain_model_path, hidden_size, question_length)\n    print('train value model begin')\n    train(cond_model, save_value_model_path, model_train_dataset, model_val_dataset, batch_size,\n          learn_rate,\n          epochs)\n    print('train value model finish')","metadata":{"execution":{"iopub.status.busy":"2024-01-16T03:48:27.022950Z","iopub.execute_input":"2024-01-16T03:48:27.023293Z","iopub.status.idle":"2024-01-16T04:09:30.558321Z","shell.execute_reply.started":"2024-01-16T03:48:27.023267Z","shell.execute_reply":"2024-01-16T04:09:30.557455Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"train column model begin\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  5.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.7845\nEpochs: 1 \n              | Train Loss:  0.5195 \n              | Val Accuracy:  0.7845\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9748\nEpochs: 2 \n              | Train Loss:  0.6749 \n              | Val Accuracy:  0.9748\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9856\nEpochs: 3 \n              | Train Loss:  0.2378 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 \n              | Train Loss:  0.1318 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 5 \n              | Train Loss:  0.1655 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 6 \n              | Train Loss:  0.1817 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 7 \n              | Train Loss:  0.1318 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 8 \n              | Train Loss:  0.1322 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 9 \n              | Train Loss:  0.1191 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 10 \n              | Train Loss:  0.1342 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 11 \n              | Train Loss:  0.1704 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 12 \n              | Train Loss:  0.1338 \n              | Val Accuracy:  0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9883\nEpochs: 13 \n              | Train Loss:  0.0967 \n              | Val Accuracy:  0.9883\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 14 \n              | Train Loss:  0.1007 \n              | Val Accuracy:  0.9834\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9896\nEpochs: 15 \n              | Train Loss:  0.1037 \n              | Val Accuracy:  0.9896\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9899\nEpochs: 16 \n              | Train Loss:  0.1007 \n              | Val Accuracy:  0.9899\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9916\nEpochs: 17 \n              | Train Loss:  0.0615 \n              | Val Accuracy:  0.9916\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9935\nEpochs: 18 \n              | Train Loss:  0.0420 \n              | Val Accuracy:  0.9935\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 19 \n              | Train Loss:  0.0425 \n              | Val Accuracy:  0.9933\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 20 \n              | Train Loss:  0.0451 \n              | Val Accuracy:  0.9895\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9963\nEpochs: 21 \n              | Train Loss:  0.0373 \n              | Val Accuracy:  0.9963\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9967\nEpochs: 22 \n              | Train Loss:  0.0254 \n              | Val Accuracy:  0.9967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 23 \n              | Train Loss:  0.0146 \n              | Val Accuracy:  0.9965\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9969\nEpochs: 24 \n              | Train Loss:  0.0317 \n              | Val Accuracy:  0.9969\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9977\nEpochs: 25 \n              | Train Loss:  0.0428 \n              | Val Accuracy:  0.9977\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9984\nEpochs: 26 \n              | Train Loss:  0.0105 \n              | Val Accuracy:  0.9984\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9993\nEpochs: 27 \n              | Train Loss:  0.0088 \n              | Val Accuracy:  0.9993\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9994\nEpochs: 28 \n              | Train Loss:  0.0045 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 29 \n              | Train Loss:  0.0124 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 30 \n              | Train Loss:  0.0165 \n              | Val Accuracy:  0.9993\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 31 \n              | Train Loss:  0.0014 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 32 \n              | Train Loss:  0.0011 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 33 \n              | Train Loss:  0.0021 \n              | Val Accuracy:  0.9993\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 34 \n              | Train Loss:  0.0086 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 35 \n              | Train Loss:  0.0042 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 36 \n              | Train Loss:  0.0125 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 37 \n              | Train Loss:  0.0025 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 38 \n              | Train Loss:  0.0017 \n              | Val Accuracy:  0.9993\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 39 \n              | Train Loss:  0.0012 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"best model | Val Accuracy:  0.9995\nEpochs: 40 \n              | Train Loss:  0.0018 \n              | Val Accuracy:  0.9995\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 41 \n              | Train Loss:  0.0006 \n              | Val Accuracy:  0.9995\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 42 \n              | Train Loss:  0.0005 \n              | Val Accuracy:  0.9995\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 43 \n              | Train Loss:  0.0004 \n              | Val Accuracy:  0.9995\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 44 \n              | Train Loss:  0.0013 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 45 \n              | Train Loss:  0.0005 \n              | Val Accuracy:  0.9993\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 46 \n              | Train Loss:  0.0031 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 47 \n              | Train Loss:  0.0004 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 48 \n              | Train Loss:  0.0123 \n              | Val Accuracy:  0.9994\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 49 \n              | Train Loss:  0.0006 \n              | Val Accuracy:  0.9995\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:10<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 50 \n              | Train Loss:  0.0004 \n              | Val Accuracy:  0.9995\ntrain column model finish\ntrain value model begin\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9834408967391305\nval_cond_vals_acc: 0.9065896739130435\nval_cond_count_acc: 0.5652173913043478\nbest model | Val Accuracy:  0.6046\nEpochs: 1 \n              | Train Loss:  1.0502 \n              | Val Accuracy:  0.6046\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9065047554347826\nval_cond_count_acc: 0.7934782608695652\nbest model | Val Accuracy:  0.8101\nEpochs: 2 \n              | Train Loss:  0.6234 \n              | Val Accuracy:  0.8101\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9325747282608695\nval_cond_count_acc: 0.967391304347826\nbest model | Val Accuracy:  0.9675\nEpochs: 3 \n              | Train Loss:  0.7179 \n              | Val Accuracy:  0.9675\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9412364130434783\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9776\nEpochs: 4 \n              | Train Loss:  0.0944 \n              | Val Accuracy:  0.9776\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9462466032608695\nval_cond_count_acc: 0.967391304347826\nEpochs: 5 \n              | Train Loss:  0.0928 \n              | Val Accuracy:  0.9680\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9487092391304348\nval_cond_count_acc: 0.967391304347826\nEpochs: 6 \n              | Train Loss:  0.1434 \n              | Val Accuracy:  0.9681\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9496433423913043\nval_cond_count_acc: 0.967391304347826\nEpochs: 7 \n              | Train Loss:  0.0573 \n              | Val Accuracy:  0.9681\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9868376358695652\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9500679347826086\nval_cond_count_acc: 0.967391304347826\nEpochs: 8 \n              | Train Loss:  0.0531 \n              | Val Accuracy:  0.9681\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9873471467391305\nval_cond_ops_acc: 0.9868376358695652\nval_cond_vals_acc: 0.9519361413043478\nval_cond_count_acc: 0.967391304347826\nEpochs: 9 \n              | Train Loss:  0.0814 \n              | Val Accuracy:  0.9682\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9920176630434783\nval_cond_ops_acc: 0.9880264945652174\nval_cond_vals_acc: 0.9546535326086957\nval_cond_count_acc: 0.967391304347826\nEpochs: 10 \n              | Train Loss:  0.0592 \n              | Val Accuracy:  0.9685\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9926970108695652\nval_cond_ops_acc: 0.9901494565217391\nval_cond_vals_acc: 0.9579653532608695\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9785\nEpochs: 11 \n              | Train Loss:  0.0301 \n              | Val Accuracy:  0.9785\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9926120923913043\nval_cond_ops_acc: 0.9911684782608695\nval_cond_vals_acc: 0.9619565217391305\nval_cond_count_acc: 0.967391304347826\nEpochs: 12 \n              | Train Loss:  0.0511 \n              | Val Accuracy:  0.9688\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9932914402173914\nval_cond_ops_acc: 0.991593070652174\nval_cond_vals_acc: 0.9650135869565217\nval_cond_count_acc: 0.967391304347826\nEpochs: 13 \n              | Train Loss:  0.0180 \n              | Val Accuracy:  0.9690\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9938009510869565\nval_cond_ops_acc: 0.9918478260869565\nval_cond_vals_acc: 0.9675611413043478\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9789\nEpochs: 14 \n              | Train Loss:  0.0203 \n              | Val Accuracy:  0.9789\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9943953804347826\nval_cond_ops_acc: 0.9922724184782609\nval_cond_vals_acc: 0.969344429347826\nval_cond_count_acc: 0.967391304347826\nEpochs: 15 \n              | Train Loss:  0.0180 \n              | Val Accuracy:  0.9692\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9955842391304348\nval_cond_ops_acc: 0.9928668478260869\nval_cond_vals_acc: 0.9710427989130435\nval_cond_count_acc: 0.967391304347826\nEpochs: 16 \n              | Train Loss:  0.0164 \n              | Val Accuracy:  0.9693\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9957540760869565\nval_cond_ops_acc: 0.9937160326086957\nval_cond_vals_acc: 0.9724864130434783\nval_cond_count_acc: 0.967391304347826\nEpochs: 18 \n              | Train Loss:  0.0237 \n              | Val Accuracy:  0.9694\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.996688179347826\nval_cond_ops_acc: 0.9943953804347826\nval_cond_vals_acc: 0.9748641304347826\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9793\nEpochs: 19 \n              | Train Loss:  0.0147 \n              | Val Accuracy:  0.9793\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9966032608695652\nval_cond_ops_acc: 0.9942255434782609\nval_cond_vals_acc: 0.9762228260869565\nval_cond_count_acc: 0.967391304347826\nEpochs: 20 \n              | Train Loss:  0.0338 \n              | Val Accuracy:  0.9696\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 53/62 [00:11<00:01,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9971127717391305\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9739300271739131\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9793\nEpochs: 21 \n              | Train Loss:  0.0329 \n              | Val Accuracy:  0.9793\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9969429347826086\nval_cond_ops_acc: 0.9946501358695652\nval_cond_vals_acc: 0.9738451086956522\nval_cond_count_acc: 0.967391304347826\nEpochs: 22 \n              | Train Loss:  0.1015 \n              | Val Accuracy:  0.9695\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9970278532608695\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9794497282608695\nval_cond_count_acc: 0.967391304347826\nEpochs: 23 \n              | Train Loss:  0.0127 \n              | Val Accuracy:  0.9697\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9971976902173914\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9807235054347826\nval_cond_count_acc: 0.967391304347826\nEpochs: 24 \n              | Train Loss:  0.0138 \n              | Val Accuracy:  0.9697\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9971976902173914\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9819123641304348\nval_cond_count_acc: 0.967391304347826\nEpochs: 25 \n              | Train Loss:  0.0123 \n              | Val Accuracy:  0.9698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9972826086956522\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9831012228260869\nval_cond_count_acc: 0.967391304347826\nEpochs: 26 \n              | Train Loss:  0.0112 \n              | Val Accuracy:  0.9698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9972826086956522\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9842900815217391\nval_cond_count_acc: 0.967391304347826\nEpochs: 27 \n              | Train Loss:  0.0134 \n              | Val Accuracy:  0.9699\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9976222826086957\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9840353260869565\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9797\nEpochs: 28 \n              | Train Loss:  0.0109 \n              | Val Accuracy:  0.9797\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9972826086956522\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9866677989130435\nval_cond_count_acc: 0.967391304347826\nEpochs: 29 \n              | Train Loss:  0.0142 \n              | Val Accuracy:  0.9700\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9975373641304348\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9866677989130435\nval_cond_count_acc: 0.967391304347826\nEpochs: 30 \n              | Train Loss:  0.0049 \n              | Val Accuracy:  0.9700\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9976222826086957\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9885360054347826\nval_cond_count_acc: 0.967391304347826\nEpochs: 31 \n              | Train Loss:  0.0127 \n              | Val Accuracy:  0.9700\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9976222826086957\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9885360054347826\nval_cond_count_acc: 0.967391304347826\nEpochs: 32 \n              | Train Loss:  0.0205 \n              | Val Accuracy:  0.9700\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9977921195652174\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9893851902173914\nval_cond_count_acc: 0.967391304347826\nEpochs: 33 \n              | Train Loss:  0.1037 \n              | Val Accuracy:  0.9701\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.997452445652174\nval_cond_ops_acc: 0.9946501358695652\nval_cond_vals_acc: 0.9898947010869565\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9798\nEpochs: 34 \n              | Train Loss:  0.0050 \n              | Val Accuracy:  0.9798\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9973675271739131\nval_cond_ops_acc: 0.9950747282608695\nval_cond_vals_acc: 0.9903192934782609\nval_cond_count_acc: 0.967391304347826\nEpochs: 35 \n              | Train Loss:  0.0168 \n              | Val Accuracy:  0.9701\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.998046875\nval_cond_ops_acc: 0.9950747282608695\nval_cond_vals_acc: 0.9897248641304348\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9799\nEpochs: 36 \n              | Train Loss:  0.0115 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9983865489130435\nval_cond_ops_acc: 0.9950747282608695\nval_cond_vals_acc: 0.9907438858695652\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9799\nEpochs: 37 \n              | Train Loss:  0.0118 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9979619565217391\nval_cond_ops_acc: 0.9951596467391305\nval_cond_vals_acc: 0.9912533967391305\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9799\nEpochs: 38 \n              | Train Loss:  0.0062 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 54/62 [00:11<00:01,  4.52it/s]","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9978770380434783\nval_cond_ops_acc: 0.9950747282608695\nval_cond_vals_acc: 0.9914232336956522\nval_cond_count_acc: 0.967391304347826\nEpochs: 39 \n              | Train Loss:  0.0130 \n              | Val Accuracy:  0.9701\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9977072010869565\nval_cond_ops_acc: 0.9949898097826086\nval_cond_vals_acc: 0.9901494565217391\nval_cond_count_acc: 0.9782608695652174\nEpochs: 40 \n              | Train Loss:  0.0062 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9979619565217391\nval_cond_ops_acc: 0.9946501358695652\nval_cond_vals_acc: 0.9833559782608695\nval_cond_count_acc: 0.9782608695652174\nEpochs: 41 \n              | Train Loss:  0.0120 \n              | Val Accuracy:  0.9796\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9978770380434783\nval_cond_ops_acc: 0.9950747282608695\nval_cond_vals_acc: 0.9904042119565217\nval_cond_count_acc: 0.9782608695652174\nEpochs: 42 \n              | Train Loss:  0.0097 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9978770380434783\nval_cond_ops_acc: 0.9952445652173914\nval_cond_vals_acc: 0.9912533967391305\nval_cond_count_acc: 0.967391304347826\nEpochs: 43 \n              | Train Loss:  0.0024 \n              | Val Accuracy:  0.9701\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9979619565217391\nval_cond_ops_acc: 0.9951596467391305\nval_cond_vals_acc: 0.9918478260869565\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9799\nEpochs: 44 \n              | Train Loss:  0.0055 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.998046875\nval_cond_ops_acc: 0.994735054347826\nval_cond_vals_acc: 0.9922724184782609\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9799\nEpochs: 45 \n              | Train Loss:  0.0030 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.998046875\nval_cond_ops_acc: 0.9949048913043478\nval_cond_vals_acc: 0.9920176630434783\nval_cond_count_acc: 0.9782608695652174\nEpochs: 46 \n              | Train Loss:  0.0032 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9981317934782609\nval_cond_ops_acc: 0.9950747282608695\nval_cond_vals_acc: 0.9917629076086957\nval_cond_count_acc: 0.9782608695652174\nEpochs: 47 \n              | Train Loss:  0.0060 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9979619565217391\nval_cond_ops_acc: 0.9946501358695652\nval_cond_vals_acc: 0.9926970108695652\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9799\nEpochs: 48 \n              | Train Loss:  0.0294 \n              | Val Accuracy:  0.9799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9978770380434783\nval_cond_ops_acc: 0.9953294836956522\nval_cond_vals_acc: 0.9925271739130435\nval_cond_count_acc: 0.9782608695652174\nbest model | Val Accuracy:  0.9800\nEpochs: 49 \n              | Train Loss:  0.0037 \n              | Val Accuracy:  0.9800\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 62/62 [00:13<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_cond_cols_acc: 0.9979619565217391\nval_cond_ops_acc: 0.9948199728260869\nval_cond_vals_acc: 0.9921875\nval_cond_count_acc: 0.9782608695652174\nEpochs: 50 \n              | Train Loss:  0.0072 \n              | Val Accuracy:  0.9799\ntrain value model finish\n","output_type":"stream"}]},{"cell_type":"code","source":"#predict\ndef predict(columns, questions, predict_result_path, pretrain_model_path, column_model_path, value_model_path,\n            hidden_size, batch_size, question_length, max_length, table_name='table_name'):\n    # 创建模型\n    col_model = ColClassifierModel(pretrain_model_path, hidden_size, len(get_agg_dict()), len(get_conn_op_dict()))\n    cond_model = CondClassifierModel(pretrain_model_path, hidden_size, question_length)\n    # 提取特征数据（不含label的数据）\n    input_features = InputFeatures(pretrain_model_path, question_length, max_length).list_features(columns, questions)\n    dataset = Dataset(input_features)\n    # 预测不用打乱顺序shuffle=False\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    # 是否使用gpu\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n    if use_cuda:\n        col_model = col_model.to(device)\n        cond_model = cond_model.to(device)\n        col_model.load_state_dict(torch.load(column_model_path, map_location=torch.device(device)))\n        cond_model.load_state_dict(torch.load(value_model_path, map_location=torch.device(device)))\n    # 预测\n    pre_all_agg = []\n    pre_all_conn_op = []\n    pre_all_cond_cols = []\n    pre_all_cond_ops = []\n    pre_all_cond_vals = []\n    pre_all_cond_counts = []\n    for input_ids, attention_mask, token_type_ids, cls_idx in tqdm(dataloader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        token_type_ids = token_type_ids.to(device)\n        out_agg, out_conn_op = col_model(input_ids, attention_mask, token_type_ids, cls_idx)\n        # 取预测结果最大值，torch.argmax找到指定纬度最大值所对应的索引（是索引，不是值）\n        pre_agg = torch.argmax(out_agg, dim=2).cpu().numpy()\n        pre_conn_op = torch.argmax(out_conn_op, dim=1).cpu().numpy()\n        pre_all_agg.extend(pre_agg)\n        pre_all_conn_op.extend(pre_conn_op)\n    for input_ids, attention_mask, token_type_ids, cls_idx in tqdm(dataloader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        token_type_ids = token_type_ids.to(device)\n        out_cond_cols, out_cond_ops, out_cond_vals, out_cond_count = cond_model(input_ids, attention_mask,\n                                                                                token_type_ids)\n        pre_cond_cols = torch.argmax(out_cond_cols, dim=2).cpu().numpy()\n        pre_cond_ops = torch.argmax(out_cond_ops, dim=2).cpu().numpy()\n        pre_cond_vals = torch.argmax(out_cond_vals, dim=2).cpu().numpy()\n        pre_cond_count = torch.argmax(out_cond_count, dim=1).cpu().numpy()\n        pre_all_cond_cols.extend(pre_cond_cols)\n        pre_all_cond_ops.extend(pre_cond_ops)\n        pre_all_cond_vals.extend(pre_cond_vals)\n        pre_all_cond_counts.extend(pre_cond_count)\n\n    with open(predict_result_path, 'w', encoding='utf-8') as wf:\n        for question, agg, conn_op, cond_cols, cond_ops, cond_vals, cond_counts in zip(questions, pre_all_agg,\n                                                                                       pre_all_conn_op,\n                                                                                       pre_all_cond_cols,\n                                                                                       pre_all_cond_ops,\n                                                                                       pre_all_cond_vals,\n                                                                                       pre_all_cond_counts):\n            sel_col = np.where(np.array(agg) != get_agg_dict()['none'])[0]\n            agg = agg[agg != get_agg_dict()['none']]\n            cond_col = cond_cols[cond_cols <= len(columns)]\n            cond_op = cond_ops[cond_ops != get_cond_op_dict()['none']]\n            sel_col_name = [columns[idx_col] for idx_col in sel_col]\n            cond_vals_name = get_values_name(question[0], cond_vals)\n            print(f'cond_col: {cond_col}')\n            print(f'cond_op: {cond_op}')\n            print(f'cond_vals_name: {cond_vals_name}')\n            print(f'cond_counts: {cond_counts}')\n            conds = [[int(cond_col[idx]), int(cond_op[idx]), cond_vals_name[idx]] for\n                     idx in range(cond_counts)]\n            sql_dict = {\"question\": question, \"table_id\": table_name,\n                        \"sql\": {\"sel\": list(map(int, sel_col)),\n                                \"agg\": list(map(int, agg)),\n                                \"limit\": 0,\n                                \"orderby\": [],\n                                \"asc_desc\": 0,\n                                \"cond_conn_op\": int(conn_op),\n                                'conds': conds},\n                        \"keywords\": {\"sel_cols\": sel_col_name, \"values\": cond_vals_name}}\n            sql_json = json.dumps(sql_dict, ensure_ascii=False)\n            wf.write(sql_json + '\\n')\n\n\nif __name__ == '__main__':\n    hidden_size = 768\n    batch_size = 12\n    question_length = 128\n    max_length = 512\n    table_path = '/kaggle/input/bert-nl2sql-train-datas/table.xlsx'\n    predict_question_path = '/kaggle/input/bert-nl2sql-train-datas/train_test.jsonl'\n    predict_result_path = '/kaggle/working/predict.jsonl'\n    pretrain_model_path = '/kaggle/input/bert-nl2sql-chinese-model-hgd'\n    column_model_path = '/kaggle/input/bert-nl2sql-result-model/classifier-column-model.pkl'\n    value_model_path = '/kaggle/input/bert-nl2sql-result-model/classifier-value-model.pkl'\n    columns = get_columns(table_path)\n    questions = read_predict_datas(predict_question_path)\n    predict(columns, questions, predict_result_path, pretrain_model_path, column_model_path, value_model_path,\n            hidden_size, batch_size, question_length, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-01-16T05:58:57.879487Z","iopub.execute_input":"2024-01-16T05:58:57.879876Z","iopub.status.idle":"2024-01-16T05:58:58.675217Z","shell.execute_reply.started":"2024-01-16T05:58:57.879846Z","shell.execute_reply":"2024-01-16T05:58:58.674254Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 37.13it/s]\n100%|██████████| 1/1 [00:00<00:00, 36.77it/s]","output_type":"stream"},{"name":"stdout","text":"cond_col: [0 3]\ncond_op: [4 4]\ncond_vals_name: ['2024-01-13', '机组']\ncond_counts: 2\ncond_col: [0 3]\ncond_op: [4 4]\ncond_vals_name: ['2024-01-13', '机组#']\ncond_counts: 2\ncond_col: [0 3]\ncond_op: [4 4]\ncond_vals_name: ['2024-01-13', '全部机', '的']\ncond_counts: 2\ncond_col: [0 0 3 3]\ncond_op: [4 6 4 4]\ncond_vals_name: ['2023-01-03', '2023-01-30', '清能#1机组']\ncond_counts: 3\ncond_col: [0 0 3 3]\ncond_op: [4 6 4]\ncond_vals_name: ['2023-01-03', '2', '023-01-30', '机组#1的出']\ncond_counts: 3\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}